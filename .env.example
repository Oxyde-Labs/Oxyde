
# API Keys
OXIDE_API_KEY=your_api_key_here

# Inference Settings
MODEL_NAME=llama2-7b
API_ENDPOINT=https://api.openai.com/v1/chat/completions
MAX_TOKENS=256
TEMPERATURE=0.7
TIMEOUT_MS=5000

# Memory Settings
MEMORY_CAPACITY=100
MEMORY_DECAY_RATE=0.05
MEMORY_THRESHOLD=0.2

# Local Model Path (if using local models)
LOCAL_MODEL_PATH=./models/llama2-7b-chat.gguf
